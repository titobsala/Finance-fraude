#version: '3.8'

services:
  zookeeper:
    image: bitnami/zookeeper:3.7
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: bitnami/kafka:3.1
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on:
      - zookeeper

  influxdb:
    image: influxdb:2.1
    ports:
      - "8086:8086"
    volumes:
      - ../data/influxdb:/var/lib/influxdb2
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=admin123
      - DOCKER_INFLUXDB_INIT_ORG=fraud-detection
      - DOCKER_INFLUXDB_INIT_BUCKET=metrics

  spark-master:
    build:
      context: ..
      dockerfile: docker/Dockerfile.spark
    container_name: spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      - SPARK_MODE=master
    healthcheck:
      test: ["CMD-SHELL", "/usr/bin/curl -s http://localhost:8080 || exit 1"]
      interval: 10s
      timeout: 20s
      retries: 6
      start_period: 60s
    volumes:
      - spark-checkpoint:/tmp/spark-checkpoint

  spark-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.spark
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - spark-checkpoint:/tmp/spark-checkpoint

  processor:
    build:
      context: ..
      dockerfile: docker/Dockerfile.processor
    depends_on:
      kafka:
        condition: service_started
      spark-master:
        condition: service_healthy
      influxdb:
        condition: service_started
    volumes:
      - ../config:/app/config 
      - ../src:/app/src
      - ../data:/app/data
      - spark-checkpoint:/tmp/spark-checkpoint
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    command: >
      sh -c "
        echo 'Waiting for Spark master to start...' &&
        sleep 20 &&
        python3 -m src.spark_processor.streaming
      "

volumes:
  spark-checkpoint:
    driver: local
    driver_opts:
      type: none
      device: ${PWD}/../data/spark-checkpoint
      o: bind